#!/usr/bin/env python3
"""
æµ‹è¯•æ–°æ—§ replan prompt çš„å¯¹æ¯”
ä½¿ç”¨çœŸå®çš„æ¢ç´¢æ•°æ®è¿›è¡Œå¯¹æ¯”
"""

import sys
import json
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from Explorer.config import ExplorerConfig
from Explorer.planner import ExplorationPlanner
from Explorer.entities import ExplorationTarget, ExplorationPlan, ExplorationStep, PerceptionOutput

def load_test_data():
    """åŠ è½½ step_11 çš„çœŸå®æµ‹è¯•æ•°æ®"""
    base_dir = Path("/Users/jackyyang/Desktop/æ¯•ä¸š/è®ºæ–‡/Fairy/integration/output/exploration/20251228_184612")

    # åŠ è½½è®¡åˆ’
    plan_file = base_dir / "plan_after_step_step_11.json"
    with open(plan_file, 'r', encoding='utf-8') as f:
        plan_data = json.load(f)

    # æ„å»º ExplorationPlan
    steps = [
        ExplorationStep(
            step_id=s['step_id'],
            instruction=s['instruction'],
            sub_goal=s['sub_goal'],
            status=s.get('status', 'pending'),
            enable_reflection=s.get('enable_reflection', True),
            max_iterations=s.get('max_iterations', 5)
        )
        for s in plan_data['steps']
    ]

    current_plan = ExplorationPlan(
        plan_thought=plan_data.get('plan_thought', ''),
        overall_plan=plan_data.get('overall_plan', ''),
        steps=steps,
        pending_steps=[s.step_id for s in steps if s.status == 'pending'],
        completed_steps=plan_data.get('completed_steps', []),
        feature_structure=plan_data.get('feature_structure', {}),
        current_feature=plan_data.get('current_feature', {}),
        feature_update=plan_data.get('feature_update')
    )

    # æ„å»º ExplorationTarget
    target = ExplorationTarget(
        app_name="Amazeæ–‡ä»¶ç®¡ç†å™¨",
        app_package="com.amaze.filemanager",
        app_description="å¼€æºæ–‡ä»¶ç®¡ç†åº”ç”¨",
        feature_to_explore="æ–‡ä»¶ï¼ˆå¤¹ï¼‰åˆ›å»ºåˆ é™¤å¤åˆ¶å‰ªåˆ‡é‡å‘½åç­‰åŠŸèƒ½",
        starting_state="é¦–é¡µ"
    )

    # æ„å»ºæœ€åä¸€æ­¥
    last_step = steps[0]  # step_11

    # æ„å»ºæœ€åæ‰§è¡Œç»“æœ
    last_result = {
        'success': True,
        'iterations': 1,
        'execution_time': 27.44
    }

    # æ„å»ºå½“å‰ perception
    step11_dir = base_dir / "step_11" / "stable"

    # è¯»å–å±å¹•æ–‡æœ¬
    compressed_txt = step11_dir / "compressed_1766919225.txt"
    with open(compressed_txt, 'r', encoding='utf-8') as f:
        screen_text = f.read()

    # æ„å»º PerceptionOutput
    current_perception = PerceptionOutput(
        screenshot_path=str(step11_dir / "screenshot_1766919225.jpeg"),
        marked_screenshot_path=str(step11_dir / "screenshot_1766919225_marked.jpeg"),
        xml_path=str(step11_dir / "ui_dump_1766919225.xml"),
        compressed_xml_path=str(step11_dir / "compressed_1766919225.xml"),
        compressed_txt_path=str(compressed_txt),
        som_mapping_path=str(step11_dir / "som_mapping_1766919225.json"),
        timestamp="1766919225",
        screen_size=(1080, 2400),
        immediate_screenshot_path=None,  # å•æˆªå›¾æ¨¡å¼
        immediate_marked_screenshot_path=None,
        immediate_xml_path=None,
        immediate_compressed_xml_path=None,
        immediate_compressed_txt_path=None,
        immediate_som_mapping_path=None
    )

    # å¯¼èˆªè·¯å¾„
    navigation_path = [
        "é¦–é¡µ",
        "åœ¨æ–°å»ºå¯¹è¯æ¡†ä¸­å®Œæˆåç§°è¾“å…¥ï¼Œè¾“å…¥æ¡†æ˜¾ç¤º\"test_new_item\"ã€‚",
        "æäº¤åç§° test_new_item å¹¶å®Œæˆæ–°å»ºæ–‡ä»¶å¤¹æ“ä½œï¼Œå…³é—­å¯¹è¯æ¡†å¹¶è¿”å›æ–‡ä»¶åˆ—è¡¨ç•Œé¢ã€‚",
        # ... å…¶ä»–è·¯å¾„
    ]

    return {
        'target': target,
        'current_plan': current_plan,
        'screen_text': screen_text,
        'last_step': last_step,
        'last_result': last_result,
        'current_perception': current_perception,
        'navigation_path': navigation_path
    }


def test_original_prompt():
    """æµ‹è¯•åŸç‰ˆ prompt"""
    print("=" * 80)
    print("æµ‹è¯•åŸç‰ˆ Replan Prompt")
    print("=" * 80)

    # åŠ è½½é…ç½®å’Œæ•°æ®
    config = ExplorerConfig(
        llm_model_name="gpt-4o",
        llm_api_key="dummy",
        llm_api_base="https://api.openai.com/v1",
        visual_model_name="gpt-4o",
        visual_api_key="dummy",
        visual_api_base="https://api.openai.com/v1",
        adb_path="/usr/local/bin/adb"
    )

    # â­ ä¸å®Œæ•´åˆå§‹åŒ–ï¼Œåªéœ€è¦ config å’Œ _get_app_specific_tips æ–¹æ³•
    # åˆ›å»ºä¸€ä¸ªæœ€å°åŒ–çš„ mock planner
    class MockPlanner:
        def __init__(self, config):
            self.config = config
            from tips_loader import get_tips_loader
            self.tips_loader = get_tips_loader()

        def _get_app_specific_tips(self, target):
            tips = self.tips_loader.get_tips_for_app(
                app_package=target.app_package,
                app_name=target.app_name
            )
            return tips if tips else ""

    planner = MockPlanner(config)

    # å¯¼å…¥å¹¶ç»‘å®šåŸç‰ˆæ–¹æ³•
    from planner import ExplorationPlanner
    planner._build_replan_prompt = ExplorationPlanner._build_replan_prompt.__get__(planner, MockPlanner)
    data = load_test_data()

    # æ„å»º promptï¼ˆä½¿ç”¨åŸç‰ˆæ–¹æ³•ï¼‰
    prompt = planner._build_replan_prompt(
        target=data['target'],
        current_plan=data['current_plan'],
        screen_text=data['screen_text'],
        last_step=data['last_step'],
        last_result=data['last_result'],
        navigation_path=data['navigation_path'],
        immediate_screen_text=None,
        feature_tree=None,
        recent_state_sequence=None
    )

    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = Path(__file__).parent / "test_output_original_prompt.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(prompt)

    # ç»Ÿè®¡ä¿¡æ¯
    line_count = len(prompt.split('\n'))
    char_count = len(prompt)

    # ä¼°ç®—tokenæ•°ï¼ˆç²—ç•¥ï¼šä¸­æ–‡1å­—â‰ˆ1.5tokenï¼Œè‹±æ–‡1è¯â‰ˆ1tokenï¼‰
    # ç®€åŒ–è®¡ç®—ï¼šæ€»å­—ç¬¦æ•° / 3
    estimated_tokens = char_count // 3

    print(f"âœ… åŸç‰ˆ Prompt å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€»è¡Œæ•°: {line_count}")
    print(f"   - æ€»å­—ç¬¦æ•°: {char_count}")
    print(f"   - ä¼°ç®—tokens: ~{estimated_tokens}")
    print()


def test_new_prompt():
    """æµ‹è¯•æ–°ç‰ˆ prompt"""
    print("=" * 80)
    print("æµ‹è¯•æ–°ç‰ˆ Replan Prompt")
    print("=" * 80)

    # å¯¼å…¥æ–°ç‰ˆæœ¬çš„å‡½æ•°
    from planner_prompt_replan_new import _build_replan_prompt_optimized

    config = ExplorerConfig(
        llm_model_name="gpt-4o",
        llm_api_key="dummy",
        llm_api_base="https://api.openai.com/v1",
        visual_model_name="gpt-4o",
        visual_api_key="dummy",
        visual_api_base="https://api.openai.com/v1",
        adb_path="/usr/local/bin/adb"
    )

    # â­ åˆ›å»ºæœ€å°åŒ–çš„ mock plannerï¼ˆåŒåŸç‰ˆæµ‹è¯•ï¼‰
    class MockPlanner:
        def __init__(self, config):
            self.config = config
            from tips_loader import get_tips_loader
            self.tips_loader = get_tips_loader()

        def _get_app_specific_tips(self, target):
            tips = self.tips_loader.get_tips_for_app(
                app_package=target.app_package,
                app_name=target.app_name
            )
            return tips if tips else ""

    planner = MockPlanner(config)
    data = load_test_data()

    # ä½¿ç”¨æ–°ç‰ˆå‡½æ•°
    prompt = _build_replan_prompt_optimized(
        planner,
        target=data['target'],
        current_plan=data['current_plan'],
        screen_text=data['screen_text'],
        last_step=data['last_step'],
        last_result=data['last_result'],
        navigation_path=data['navigation_path'],
        immediate_screen_text=None,
        feature_tree=None,
        recent_state_sequence=None
    )

    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = Path(__file__).parent / "test_output_new_prompt.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(prompt)

    # ç»Ÿè®¡ä¿¡æ¯
    line_count = len(prompt.split('\n'))
    char_count = len(prompt)
    estimated_tokens = char_count // 3

    print(f"âœ… æ–°ç‰ˆ Prompt å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€»è¡Œæ•°: {line_count}")
    print(f"   - æ€»å­—ç¬¦æ•°: {char_count}")
    print(f"   - ä¼°ç®—tokens: ~{estimated_tokens}")
    print()


def compare_prompts():
    """å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬"""
    print("=" * 80)
    print("å¯¹æ¯”åˆ†æ")
    print("=" * 80)

    original_file = Path(__file__).parent / "test_output_original_prompt.txt"
    new_file = Path(__file__).parent / "test_output_new_prompt.txt"

    if not original_file.exists():
        print("âŒ åŸç‰ˆè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ test_original_prompt()")
        return

    if not new_file.exists():
        print("âŒ æ–°ç‰ˆè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ test_new_prompt()")
        return

    with open(original_file, 'r', encoding='utf-8') as f:
        original = f.read()

    with open(new_file, 'r', encoding='utf-8') as f:
        new = f.read()

    orig_lines = len(original.split('\n'))
    new_lines = len(new.split('\n'))

    orig_chars = len(original)
    new_chars = len(new)

    orig_tokens = orig_chars // 3
    new_tokens = new_chars // 3

    print(f"ğŸ“Š å¯¹æ¯”ç»“æœ:")
    print(f"   è¡Œæ•°:    {orig_lines:5d} â†’ {new_lines:5d} (å˜åŒ–: {new_lines - orig_lines:+d}, {(new_lines - orig_lines) / orig_lines * 100:+.1f}%)")
    print(f"   å­—ç¬¦æ•°:  {orig_chars:5d} â†’ {new_chars:5d} (å˜åŒ–: {new_chars - orig_chars:+d}, {(new_chars - orig_chars) / orig_chars * 100:+.1f}%)")
    print(f"   ä¼°ç®—tokens: {orig_tokens:5d} â†’ {new_tokens:5d} (å˜åŒ–: {new_tokens - orig_tokens:+d}, {(new_tokens - orig_tokens) / orig_tokens * 100:+.1f}%)")
    print()
    print(f"ğŸ’¾ ä½¿ç”¨ diff å·¥å…·å¯¹æ¯”ä¸¤ä¸ªæ–‡ä»¶:")
    print(f"   diff {original_file} {new_file}")
    print(f"   æˆ–ä½¿ç”¨ VS Code: code -d {original_file} {new_file}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æµ‹è¯• replan prompt æ–°æ—§ç‰ˆæœ¬å¯¹æ¯”")
    parser.add_argument('--mode', choices=['original', 'new', 'compare', 'all'],
                        default='all', help='æµ‹è¯•æ¨¡å¼')

    args = parser.parse_args()

    if args.mode in ['original', 'all']:
        test_original_prompt()

    if args.mode in ['new', 'all']:
        try:
            test_new_prompt()
        except Exception as e:
            print(f"âŒ æ–°ç‰ˆæµ‹è¯•å¤±è´¥: {e}")
            print("æç¤º: è¯·ç¡®ä¿ planner_prompt_replan_new.py ä¸­çš„å‡½æ•°æ­£ç¡®å®ç°")

    if args.mode in ['compare', 'all']:
        compare_prompts()
